{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64  # Latent space dimension\n",
    "NUM_EMBEDDINGS = 128  # Number of vectors in codebook\n",
    "COMMITMENT_COST = 0.25  # Beta in loss function\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform),\n",
    "    batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack(h, num_hiddens, num_residual_layers):\n",
    "    for _ in range(num_residual_layers):\n",
    "        h = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_hiddens, num_hiddens, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_hiddens, num_hiddens, kernel_size=1, stride=1, padding=0)\n",
    "        )(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming from x -> z_e\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, latent_dim, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)  # No activation, raw latents\n",
    "        residual_stack(x, self.latent_dim, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_e -> z_q Codebook Dimension\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape  # Get input shape\n",
    "        x_flattened = x.permute(0, 2, 3, 1).contiguous().view(-1, C)\n",
    "        distances = torch.cdist(x_flattened, self.embedding.weight)\n",
    "        encoding_indices = torch.argmin(distances, dim=1)\n",
    "        quantized = self.embedding(encoding_indices).view(B, H, W, C).permute(0, 3, 1, 2).contiguous()\n",
    "        \n",
    "        loss = F.mse_loss(quantized.detach(), x) + self.commitment_cost * F.mse_loss(x.detach(), quantized)\n",
    "        quantized = x + (quantized - x).detach()\n",
    "        \n",
    "        return quantized, loss, encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_q -> x_hat Decoding\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv1 = nn.ConvTranspose2d(latent_dim, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        residual_stack(x, self.latent_dim, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.sigmoid(self.conv3(x))  # Output in [0,1]\n",
    "        return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.encoder = Encoder(embedding_dim)\n",
    "        self.quantizer = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n",
    "        self.decoder = Decoder(embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_e = self.encoder(x)\n",
    "        z_q, loss, encoding_indices = self.quantizer(z_e)\n",
    "        x_hat = self.decoder(z_q)\n",
    "        return x_hat, loss, encoding_indices\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.quantizer(self.encoder(x))[2]\n",
    "    \n",
    "    def decode(self, x):\n",
    "\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 269.72688640654087\n",
      "Test Loss: 4.80166812799871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:46<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 234.70489698648453\n",
      "Test Loss: 5.644162658601999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 232.2381955087185\n",
      "Test Loss: 5.816103123128414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 231.82415072619915\n",
      "Test Loss: 5.777996052056551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:47<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 231.02096800506115\n",
      "Test Loss: 5.462233379483223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 231.0625822097063\n",
      "Test Loss: 5.218217071145773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 231.1532829552889\n",
      "Test Loss: 5.472422294318676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:49<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 230.947411775589\n",
      "Test Loss: 5.497206225991249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:48<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 230.2450854331255\n",
      "Test Loss: 4.939288141205907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:49<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 229.2881696075201\n",
      "Test Loss: 5.166347183287144\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.169509029015899\n"
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_loader, test_loader):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "\n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for batch, _ in tqdm(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                def add_noise(x):\n",
    "                    return np.clip(x + torch.randn_like(x) * 0.1, 0, 1)\n",
    "                batch = add_noise(batch)\n",
    "                x_hat, loss, _ = self.model(batch)\n",
    "                loss_1 = F.binary_cross_entropy(x_hat, batch)\n",
    "                loss = loss.mean()\n",
    "                loss += loss_1\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            self.train_losses.append(train_loss)\n",
    "            print(f\"Epoch {epoch}: Train Loss: {train_loss}\")\n",
    "            self.test()\n",
    "    \n",
    "    def visualize_reconstructions(self, n=5\n",
    "    ):\n",
    "        self.model.eval()\n",
    "        for batch, _ in self.test_loader:\n",
    "            x_hat, _, idx = self.model(batch)\n",
    "            for i in range(n):\n",
    "                plt.subplot(2, n, i+1)\n",
    "                plt.imshow(batch[i].squeeze().detach().numpy(), cmap=\"gray\")\n",
    "                plt.subplot(2, n, i+1+n)\n",
    "                plt.imshow(x_hat[i].squeeze().detach().numpy(), cmap=\"gray\")\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        for batch, _ in self.test_loader:\n",
    "            x_hat, loss, _ = self.model(batch)\n",
    "            loss = loss.mean()\n",
    "            test_loss += loss.item()\n",
    "        self.test_losses.append(test_loss)\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "model = VQVAE(NUM_EMBEDDINGS, LATENT_DIM, COMMITMENT_COST)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "trainer = Trainer(model, optimizer, train_loader, test_loader)\n",
    "trainer.train(10)\n",
    "trainer.visualize_reconstructions()\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=16, dropout_prob=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_layer_1 = nn.Linear(num_items, 256)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.dense_layer_2 = nn.Linear(256, 64)  \n",
    "        self.batch_norm = nn.BatchNorm1d(64)  \n",
    "        \n",
    "        self.dense_layer_3 = nn.Linear(64, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense_layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.batch_norm(self.dense_layer_2(x)))\n",
    "        x = self.dense_layer_3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=16, dropout_prob=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_layer_1 = nn.Linear(embedding_dim, 64)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.dense_layer_2 = nn.Linear(64, 256)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.dense_layer_3 = nn.Linear(256, num_items)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_layer_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dense_layer_2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense_layer_3(x)  \n",
    "        x = torch.sigmoid(x)  # Assuming binary or bounded output\n",
    "        return x\n",
    "    \n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost=0.25):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "\n",
    "        # Create embedding codebook\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / num_embeddings, 1.0 / num_embeddings)\n",
    "\n",
    "    def forward(self, z_e):\n",
    "        # Compute distances between latent vectors and codebook vectors\n",
    "        z_e_reshaped = z_e.view(-1, self.embedding_dim)  # Flatten for processing\n",
    "        distances = torch.cdist(z_e_reshaped, self.embedding.weight)  # L2 distances\n",
    "\n",
    "        # Find nearest codebook vector\n",
    "        encoding_indices = torch.argmin(distances, dim=1)\n",
    "        z_q = self.embedding(encoding_indices).view(z_e.shape)\n",
    "\n",
    "        # Compute commitment loss\n",
    "        loss = F.mse_loss(z_q.detach(), z_e) + self.commitment_cost * F.mse_loss(z_e.detach(), z_q)\n",
    "\n",
    "        return z_q, encoding_indices, loss\n",
    "    \n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, num_embeddings):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, latent_dim)\n",
    "        self.quantizer = VectorQuantizer(num_embeddings, latent_dim)\n",
    "        self.decoder = Decoder(input_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_e = self.encoder(x)\n",
    "        z_q, encodings, vq_loss = self.quantizer(z_e)\n",
    "        x_reconstructed = self.decoder(z_q)\n",
    "        return x_reconstructed, vq_loss, encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE_Rec_Sys:\n",
    "    def __init__(self, dataset, num_items, embedding_dim=16, num_embeddings=128, **config):\n",
    "        # Initialize the model components\n",
    "        self.dataset = dataset\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.model = VQVAE(input_dim=num_items, hidden_dim=64, latent_dim=embedding_dim, num_embeddings=num_embeddings)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def train(self, epochs=10, batch_size=32):\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for i in range(0, len(self.dataset), batch_size):\n",
    "                # Get the batch from the dataset\n",
    "                batch_data = self.dataset[i:i+batch_size]\n",
    "                batch_data = torch.tensor(batch_data, dtype=torch.float32).to(self.device)\n",
    "                \n",
    "                # Zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass through the model\n",
    "                x_reconstructed, vq_loss, _ = self.model(batch_data)\n",
    "\n",
    "                # Compute reconstruction loss\n",
    "                recon_loss = F.mse_loss(x_reconstructed, batch_data)\n",
    "\n",
    "                # Total loss = reconstruction loss + VQ loss\n",
    "                loss = recon_loss + vq_loss\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Backward pass and optimizer step\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Print the loss for this epoch\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(self.dataset)}\")\n",
    "\n",
    "    def recommend_items(self, user_index, top_k=5):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Generate the input vector for the user (e.g., user-item interaction vector)\n",
    "        user_data = self.dataset[user_index]\n",
    "        user_data = torch.tensor(user_data, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "\n",
    "        # Forward pass to get reconstructed preferences\n",
    "        with torch.no_grad():\n",
    "            x_reconstructed, _, encodings = self.model(user_data)\n",
    "\n",
    "        # After reconstruction, we use the encoder's output (latent representation)\n",
    "        # Here we just use the reconstructed values to recommend items\n",
    "        # For simplicity, we take the reconstructed output and find the top-k items\n",
    "\n",
    "        reconstructed_preferences = x_reconstructed.squeeze().cpu().numpy()\n",
    "\n",
    "        # Get the top K most recommended items\n",
    "        recommended_items = reconstructed_preferences.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        return recommended_items\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.train_losses, label=\"Train Loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_18880\\1854203390.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_data = torch.tensor(batch_data, dtype=torch.float32).to(self.device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x4175 and 500x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m dataset = torch.FloatTensor(inter_matr)\n\u001b[32m      7\u001b[39m rec_sys = VQVAE_Rec_Sys(dataset, num_items=\u001b[32m500\u001b[39m, embedding_dim=\u001b[32m16\u001b[39m, num_embeddings=\u001b[32m128\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mrec_sys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#rec_sys.plot_loss()\u001b[39;00m\n\u001b[32m     11\u001b[39m recommended_items = rec_sys.recommend_items(user_index=\u001b[32m0\u001b[39m, top_k=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mVQVAE_Rec_Sys.train\u001b[39m\u001b[34m(self, epochs, batch_size)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m x_reconstructed, vq_loss, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Compute reconstruction loss\u001b[39;00m\n\u001b[32m     29\u001b[39m recon_loss = F.mse_loss(x_reconstructed, batch_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mVQVAE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     z_e = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     z_q, encodings, vq_loss = \u001b[38;5;28mself\u001b[39m.quantizer(z_e)\n\u001b[32m     83\u001b[39m     x_reconstructed = \u001b[38;5;28mself\u001b[39m.decoder(z_q)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     x = F.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense_layer_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     15\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.batch_norm(\u001b[38;5;28mself\u001b[39m.dense_layer_2(x)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Justin\\Documents\\Master-Thesis\\residual-quantization\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (32x4175 and 500x256)"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/lfm_interactions.csv', sep=\"\\t\", index_col=0)\n",
    "inter_matr = pd.pivot_table(df, values='count', index='user_id', columns='item_id')\n",
    "inter_matr = inter_matr.fillna(0).to_numpy()\n",
    "inter_matr = (inter_matr > 0).astype(int)\n",
    "\n",
    "dataset = torch.FloatTensor(inter_matr)\n",
    "rec_sys = VQVAE_Rec_Sys(dataset, num_items=500, embedding_dim=16, num_embeddings=128)\n",
    "rec_sys.train(epochs=10)\n",
    "#rec_sys.plot_loss()\n",
    "\n",
    "recommended_items = rec_sys.recommend_items(user_index=0, top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
